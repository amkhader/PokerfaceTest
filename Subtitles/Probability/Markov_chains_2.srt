1
00:00:01,000 --> 00:00:04,843
Bernoulli refined the idea of expectation.

2
00:00:04,844 --> 00:00:07,552
He was focused on a method
of accurately estimating

3
00:00:07,552 --> 00:00:11,081
the unknown probability
of some event based on

4
00:00:11,081 --> 00:00:16,034
the number of times the event
occurs in independent trials.

5
00:00:16,034 --> 00:00:17,987
He uses a simple example.

6
00:00:17,987 --> 00:00:20,412
Suppose that without your knowledge,

7
00:00:20,412 --> 00:00:23,966
3,000 light pebbles and 2,000 dark pebbles

8
00:00:23,966 --> 00:00:26,902
are hidden in an urn,
and that to determine

9
00:00:26,902 --> 00:00:30,442
the ratio of white versus
black by experiment,

10
00:00:30,443 --> 00:00:32,933
you draw one pebble after another,

11
00:00:32,933 --> 00:00:36,027
with replacement, and note how many times

12
00:00:36,027 --> 00:00:41,115
a white pebble is drawn versus black.

13
00:00:41,115 --> 00:00:42,890
He went on to prove
that the expected value

14
00:00:42,890 --> 00:00:45,378
of white versus black observations

15
00:00:45,378 --> 00:00:47,778
will converge on the actual ratio

16
00:00:47,778 --> 00:00:50,877
as the number of trials increases,

17
00:00:50,877 --> 00:00:54,264
known as the weak law of large numbers.

18
00:00:56,521 --> 00:00:59,124
He concluded by saying, "If observations

19
00:00:59,124 --> 00:01:02,660
"of all events be continued
for the entire infinity,

20
00:01:02,660 --> 00:01:04,773
"it will be noticed that
everything in the world

21
00:01:04,773 --> 00:01:06,880
"is governed by precise ratios

22
00:01:06,880 --> 00:01:10,245
"and a constant law of change."

23
00:01:10,245 --> 00:01:12,107
This idea was quickly extended

24
00:01:12,107 --> 00:01:13,455
as it was noticed that not only

25
00:01:13,456 --> 00:01:16,390
did things converge on
an expected average,

26
00:01:16,390 --> 00:01:20,105
but the probability of
variation away from averages

27
00:01:20,105 --> 00:01:24,220
also follow a familiar, underlying shape,

28
00:01:24,220 --> 00:01:26,430
or distribution.

29
00:01:26,430 --> 00:01:29,948
A great example of this is
Francis Galton's bean machine.

30
00:01:29,948 --> 00:01:33,692
Imagine each collision as
a single independent event,

31
00:01:33,692 --> 00:01:35,460
such as a coin flip.

32
00:01:35,460 --> 00:01:37,827
After 10 collisions or events,

33
00:01:37,827 --> 00:01:40,422
the bean falls into a bucket representing

34
00:01:40,422 --> 00:01:43,353
the ratio of left versus right deflection,

35
00:01:43,354 --> 00:01:45,376
or heads versus tails.

36
00:01:45,376 --> 00:01:48,964
This overall curvature, known
as the binomial distribution,

37
00:01:48,964 --> 00:01:50,868
appears to be an ideal form

38
00:01:50,868 --> 00:01:52,901
as it kept appearing everywhere

39
00:01:52,902 --> 00:01:54,953
any time you looked at the variation

40
00:01:54,953 --> 00:01:57,978
of a large number of random trials.

41
00:01:59,333 --> 00:02:02,038
It seems the average fate of these events

42
00:02:02,038 --> 00:02:05,003
is somehow predetermined, known today

43
00:02:05,003 --> 00:02:07,533
as the central limit theorem.
